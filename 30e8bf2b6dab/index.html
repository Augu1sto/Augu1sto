<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>【论文阅读】GIScience21-LSTM-TrajGAN·A Deep Learning Approach to Trajectory Privacy Protection | 若叶</title><meta name="keywords" content="轨迹,隐私保护,GAN"><meta name="author" content="Augu1sto"><meta name="copyright" content="Augu1sto"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="论文基本信息⁍  作者：Jinmeng Rao等（威斯康星） 年份：2021 会议&#x2F;期刊：GIScience 相关下载：  LSTM-TrajGAN: A Deep Learning Approach to Trajectory Privacy Protection (dagstuhl.de)   阅读参考：无  本人之前课程报告的slides 👉 提取码：zrs9   开源信息： github">
<meta property="og:type" content="article">
<meta property="og:title" content="【论文阅读】GIScience21-LSTM-TrajGAN·A Deep Learning Approach to Trajectory Privacy Protection">
<meta property="og:url" content="https://augu1sto.github.io/augu1sto/30e8bf2b6dab/index.html">
<meta property="og:site_name" content="若叶">
<meta property="og:description" content="论文基本信息⁍  作者：Jinmeng Rao等（威斯康星） 年份：2021 会议&#x2F;期刊：GIScience 相关下载：  LSTM-TrajGAN: A Deep Learning Approach to Trajectory Privacy Protection (dagstuhl.de)   阅读参考：无  本人之前课程报告的slides 👉 提取码：zrs9   开源信息： github">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://augu1sto.github.io/augu1sto/img/cover02.jpg">
<meta property="article:published_time" content="2021-12-24T10:22:43.000Z">
<meta property="article:modified_time" content="2021-12-29T13:28:47.449Z">
<meta property="article:author" content="Augu1sto">
<meta property="article:tag" content="轨迹">
<meta property="article:tag" content="隐私保护">
<meta property="article:tag" content="GAN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://augu1sto.github.io/augu1sto/img/cover02.jpg"><link rel="shortcut icon" href="/augu1sto/img/favicon.png"><link rel="canonical" href="https://augu1sto.github.io/augu1sto/30e8bf2b6dab/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="baidu-site-verification" content="code-oEsTyOVPwJ"/><link rel="stylesheet" href="/augu1sto/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/augu1sto/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '【论文阅读】GIScience21-LSTM-TrajGAN·A Deep Learning Approach to Trajectory Privacy Protection',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-12-29 21:28:47'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    document.addEventListener('pjax:complete', detectApple)})(window)</script><meta name="google-site-verification" content="a1IrzpkO5Jd9_eZl1_IwZSZ779M4c5LPUf7oSBp4G58" /><link rel="stylesheet" href="/self/material.css"><link rel="stylesheet" href="/css/custom.css"  media="defer" onload="this.media='all'"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/augu1sto/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/augu1sto/archives/"><div class="headline">文章</div><div class="length-num">79</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/augu1sto/tags/"><div class="headline">标签</div><div class="length-num">58</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/augu1sto/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/augu1sto/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/augu1sto/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/augu1sto/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/augu1sto/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/augu1sto/messageboard/"><i class="fa-fw fas fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/augu1sto/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/augu1sto/projects/smartncc/doc/"><i class="fa-fw fas fa-arrow-up-right-from-square"></i><span> 我的项目</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/augu1sto/img/cover02.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/augu1sto/">若叶</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/augu1sto/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/augu1sto/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/augu1sto/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/augu1sto/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/augu1sto/messageboard/"><i class="fa-fw fas fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/augu1sto/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/augu1sto/projects/smartncc/doc/"><i class="fa-fw fas fa-arrow-up-right-from-square"></i><span> 我的项目</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【论文阅读】GIScience21-LSTM-TrajGAN·A Deep Learning Approach to Trajectory Privacy Protection</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-12-24T10:22:43.000Z" title="发表于 2021-12-24 18:22:43">2021-12-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-12-29T13:28:47.449Z" title="更新于 2021-12-29 21:28:47">2021-12-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/augu1sto/categories/%E8%BD%A8%E8%BF%B9%E5%90%88%E6%88%90/">轨迹合成</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="【论文阅读】GIScience21-LSTM-TrajGAN·A Deep Learning Approach to Trajectory Privacy Protection"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="论文基本信息">论文基本信息<a class="header-anchor" href="#论文基本信息">⁍</a></h2>
<ul>
<li>作者：Jinmeng Rao等（威斯康星）</li>
<li>年份：2021</li>
<li>会议/期刊：GIScience</li>
<li>相关下载：
<ul>
<li><a target="_blank" rel="noopener" href="https://drops.dagstuhl.de/opus/volltexte/2020/13047/pdf/LIPIcs-GIScience-2021-I-12.pdf">LSTM-TrajGAN: A Deep Learning Approach to Trajectory Privacy Protection (dagstuhl.de)</a></li>
</ul>
</li>
<li>阅读参考：无
<ul>
<li>本人之前课程报告的slides 👉 <a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1vwUYn7c9l43Y5nW3MzL0jA">提取码：zrs9</a></li>
</ul>
</li>
<li>开源信息： <a target="_blank" rel="noopener" href="https://github.com/GeoDS/LSTM-TrajGAN">github</a> (实验评估只有TUL)</li>
<li>简介：一种端到端的深度学习方法来生成保护隐私的轨迹数据，同时可以保留语义信息（POI）。主要采用LSTM+GAN网络并设计了一个新的TrajLoss度量函数
<ul>
<li>模型名称：LSTM-TrajGAN</li>
<li>数据集： NYC Foursquare weekly trajectory dataset（originally come from <a target="_blank" rel="noopener" href="https://sites.google.com/site/yangdingqi/home/foursquare-dataset">the Foursquare NYC check-in dataset</a>）</li>
</ul>
</li>
</ul>
<hr>
<blockquote>
<p>是之前做课程报告的时候看的论文，做的笔记可能比较啰嗦。。</p>
</blockquote>
<hr>
<h2 id="abstract">Abstract<a class="header-anchor" href="#abstract">⁍</a></h2>
<ul>
<li>
<p>问题背景：</p>
<ul>
<li>基于位置的服务的普及促进了个人水平轨迹数据的爆炸性增长，并引起了公众对隐私问题的关注。</li>
</ul>
</li>
<li>
<p>方法：</p>
<ul>
<li>在这项研究中，我们提出了一种新颖的LSTM-TrajGAN方法，这是一种端到端的深度学习模型，用于生成保存隐私的合成轨迹数据以进行数据共享和发布。</li>
<li>我们设计了一种损失度量函数TrajLoss来测量轨迹相似性损失，以进行模型训练和优化。</li>
</ul>
</li>
<li>
<p>实验与评估：</p>
<ul>
<li>在真实世界语义轨迹数据集上的轨迹用户链接任务上对模型进行评估。</li>
<li>与其他常见的地理掩蔽方法相比，我们的模型可以更好地防止用户被重新识别，并且还保留了真实轨迹数据的基本空间，时间和主题特征。</li>
<li>该模型更好地平衡了轨迹隐私保护的有效性和用于时空分析的实用程序，从而为基于GeoAI的隐私保护提供了新的见解。</li>
</ul>
</li>
</ul>
<h2 id="1-introduction">1. Introduction<a class="header-anchor" href="#1-introduction">⁍</a></h2>
<h3 id="问题背景">问题背景<a class="header-anchor" href="#问题背景">⁍</a></h3>
<h4 id="基于位置服务（lbs-location-based-services）带来的隐私问题">基于位置服务（LBS, Location-Based Services）带来的隐私问题<a class="header-anchor" href="#基于位置服务（lbs-location-based-services）带来的隐私问题">⁍</a></h4>
<ul>
<li>越来越多的基于位置的服务（LBS）已通过移动电话，可穿戴式传感器，GPS设备和带有地理标签的社交媒体<strong>生成了大规模的个人级轨迹数据</strong>（即具有属性的位置序列）[19]。</li>
<li>**作用：**这样的轨迹大数据为研究人类流动模式和人与环境之间的相互作用[11]，灾害应对[12、27]和公共卫生问题[17、25]提供了新的机会。 它还提出了有关保护地缘和更大范围的行为，社会，道德，法律和政策影响的挑战[14]。</li>
<li><strong>轨迹隐私：</strong> 一般来说，轨迹隐私是指个人的权利，以防止泄露个人轨迹身份和相关的个人敏感位置[15、2、5]。</li>
</ul>
<h4 id="问题挑战？">问题挑战？<a class="header-anchor" href="#问题挑战？">⁍</a></h4>
<p>由于数据泄露问题和公众对位置隐私保护意识的增强，已经提出了许多方法来防止识别用户的轨迹。</p>
<ol>
<li>
<p>从轨迹数据中删除标识符（例如，用户名或ID号）。</p>
<p>【问题】这种“去识别的de-identified”轨迹仍然可能造成严重的隐私威胁，因为轨迹的空间，时间和主题特征仍然可以用作将轨迹链接到其创建者的强有力的准标识符</p>
</li>
<li>
<p>将轨迹点聚合到地理或行政单位中，这样就不会显示其原始位置。</p>
<p>【问题】最近的研究表明聚合可能无法保留用户隐私并降低空间分辨率和空间分析的有效性[3，28，5]</p>
<p>De Montjoye等[3]通过空间和时间聚合降低人类移动性轨迹数据集的分辨率，以防止个人被识别，但是经过粗化的数据集仅提供很少的匿名性。</p>
</li>
</ol>
<p>==&gt;为了更有效地实现轨迹隐私保护,需要更全面地处理轨迹数据的时空特征。</p>
<h3 id="现有研究">现有研究<a class="header-anchor" href="#现有研究">⁍</a></h3>
<p>当前的轨迹隐私保护研究主要集中在两个研究领域。</p>
<ol>
<li>
<p>差分隐私(?)</p>
<p>对来自不同用户的轨迹进行分组和混合，以便将单个轨迹数据的标识转换为k-匿名问题</p>
<ul>
<li>空间伪装spatial cloaking方法将 k 用户之间的轨迹点，用 k 匿名隐藏的空间区域混合在一起，使这些轨迹 k 匿名化</li>
</ul>
</li>
<li>
<p>混合区mix-zone方法使用化名使混合区中的轨迹点匿名化，并打破了通过混合区的同一轨迹的前段和后段之间的联系</p>
</li>
<li>
<p>基于泛化的方法generalization-based approach首先将k个轨迹的点划分为不同的k个匿名区域，然后通过从每个k个匿名区域中均匀选择点并将它们链接在一起来重建k个新轨迹</p>
</li>
<li>
<p>地理掩蔽geomasking</p>
<p>利用空间维度上的扰动来模糊原始轨迹数据的位置，以便可以隐藏或修改原始位置，而不会严重影响空间模式</p>
<ul>
<li>Armstrong等[1]探索了几种类型的地罩的隐私保护能力和空间分析有效性。 关等。</li>
<li>[15]评估了三种不同的随机扰动地罩对肺癌死亡的空间分析效果。</li>
<li>Seidl等[26]在GPS轨迹数据上应用了网格掩蔽和随机扰动，并评估了隐私保护性能。</li>
<li>高等[5]研究了随机扰动，高斯扰动和Twitter数据聚合的有效性，并探讨了每种方法的隐私，分析和不确定性级别。</li>
</ul>
</li>
</ol>
<p><strong>限制</strong></p>
<ul>
<li>**轨迹隐私保护的有效性与时空分析的实用性之间的权衡：**尽管存在多样性，但这些方法的目标主要是混淆轨迹位置并增加更多不确定性（噪声）以保护隐私。但是，轨迹隐私保护的有效性与时空分析的实用性之间的权衡仍然难以控制</li>
<li>当前的研究主要集中在轨迹数据的空间维度上，而很少考虑其他语义（例如，时间和主题属性）。实际上，这些特性已被证明对于轨迹用户识别至关重要[21]</li>
<li>自动化：当前的方法严重依赖于手动设计的程序。 一旦公开了该程序，就可能有机会恢复原始轨迹数据[28]（例如，使用逆向工程）。 <strong>“黑匣子”机器学习模型可能有助于解决此问题。</strong></li>
</ul>
<blockquote>
<p>‘黑匣子机器学习模型’？</p>
</blockquote>
<h3 id="方法提出">方法提出<a class="header-anchor" href="#方法提出">⁍</a></h3>
<p>本研究旨在<strong>探索先进的深度学习方法对轨迹隐私保护的有效性</strong>。</p>
<p>我们提出了一种新颖的LSTM-TrajGAN模型，该模型将长短期记忆（LSTM）递归神经网络和生成对抗网络（GAN）结构结合在一起，以生成保留隐私的合成轨迹，作为真实轨迹的替代方案，用于轨迹数据共享和发布 。</p>
<h4 id="两个研究问题（rq）">两个研究问题（RQ）<a class="header-anchor" href="#两个研究问题（rq）">⁍</a></h4>
<p><strong>RQ1:</strong> 提议的LSTM-TrajGAN模型在保护轨迹创建者免于重新识别方面有多有效？ （即，隐私保护有效性）</p>
<p>**RQ2：**与真实轨迹相比，合成轨迹能否保留语义特征（时空主题特征）？ （即实用性）</p>
<h3 id="主要贡献">主要贡献<a class="header-anchor" href="#主要贡献">⁍</a></h3>
<p>（1）我们提出了一种端到端的深度学习方法来生成保护隐私的轨迹数据。 该过程既简单又高度安全（GeoAI“黑匣子”）；</p>
<p>（2）介绍了一种用于语义轨迹编码的轨迹编码模型。</p>
<p>（3）我们设计了一个新的TrajLoss度量函数，以测量训练深度学习模型的轨迹相似性损失；</p>
<p>（4）我们使用真实的LBS数据评估了该模型的隐私保护有效性和实用性，并探讨了两者之间的取舍。</p>
<h2 id="2-method">2. Method<a class="header-anchor" href="#2-method">⁍</a></h2>
<p>受TrajGAN [18]的版本的启发，我们提出了一种新的方法，该方法包括三个主要部分：</p>
<p>（1）轨迹编码模型，该模型编码GPS位置坐标，时间属性以及其他属性，例如兴趣点（POI） 类别;</p>
<blockquote>
<p>POI兴趣点（Point Of Interest）是地理信息系统范畴中的一个概念，指可以抽象为点的地理对象，尤其是一些与人们生活密切相关的地理实体，如学校、银行、餐馆、加油站、医院、超市、公交站等。兴趣点的主要用途是对事物或事件的地址进行描述，能在很大程度上增强对事物或事件位置的描述能力和查询能力。</p>
<p>POI通常包含地理对象的名称，位置，类别等信息，随着大数据时代的来临，POI兴趣点被广泛应用于各行各业，包括科研、教育、交通、能源、互联网、旅游、城市、经济、公共应急管理、园区管理、房产、通讯、土建、规划及其相关行业等等。</p>
<p>POI的采集是一个非常耗时费力的工作，因此，POI的数量在一定程度代表着其本身的价值。</p>
<p><a target="_blank" rel="noopener" href="http://gaohr.win/site/blogs/2019/2019-12-10-baidu-map-poi-cn.html">http://gaohr.win/site/blogs/2019/2019-12-10-baidu-map-poi-cn.html</a></p>
</blockquote>
<p>（2）轨迹生成器，其以随机噪声和原始轨迹为输入，以生成合成轨迹为输出；</p>
<p>（3）轨迹鉴别器，将轨迹作为输入并将其确定为“真实”或“合成”。</p>
<p><img src="https://gitee.com/Augu1sto/imageHost/raw/master/BlogImg/202112241854770.png" alt="image-20211224185436708"></p>
<p>总体工作流程如图1所示。目标是<strong>训练一个“智能”轨迹生成器</strong>，该生成器生成“现实”合成轨迹来替换原始轨迹，从而在轨迹分析任务（例如轨迹用户链接（TUL））和轨迹数据挖掘（例如，工作/家庭位置聚类）中保留差异隐私。  同时，它确保了多个时空摘要分析任务的质量。 这样的框架可以充当轨迹数据获取，处理和发布管道中的轨迹隐私保护层，这些渠道发布合成的替代方案，而不是可能公开个人隐私的真实轨迹数据。</p>
<h3 id="2-1-trajectory-encoding">2.1 Trajectory Encoding<a class="header-anchor" href="#2-1-trajectory-encoding">⁍</a></h3>
<p>引入一个轨迹编码模型，该模型将原始轨迹数据转换为一种特定的格式，作为LSTM-TrajGAN模型的输入</p>
<p>进行编码的主要原因是轨迹数据通常包含各种类型的属性，例如间隔数据（例如GPS坐标，日期和时间），标称数据（例如POI类别），序数数据（例如POI等级） ，并且需要将这些数据转换为有效的数字表示形式，以训练深度学习模型。</p>
<p>包括两个部分：轨迹点编码和轨迹填充</p>
<h4 id="轨迹点编码trajectory-point-encoding">轨迹点编码Trajectory Point Encoding<a class="header-anchor" href="#轨迹点编码trajectory-point-encoding">⁍</a></h4>
<p><img src="https://gitee.com/Augu1sto/imageHost/raw/master/BlogImg/202112241855714.png" alt="image-20211224185502635"></p>
<ul>
<li>
<p>语义轨迹点包含以下属性：位置，时间，用户ID，轨迹ID和其他可选属性（例如POI类别）。</p>
</li>
<li>
<p>对于location属性，我们使用数据集中所有轨迹的质心标准化所有纬度和经度，以获得纬度和经度与质心的偏差。 这样，模型可以更好地了解不同轨迹点之间的空间偏差模式。（？） 这些偏差值将被用作构建空间嵌入的轨迹点的数字表示</p>
</li>
<li>
<p>对于时间属性和分类属性，我们使用One-Hot编码(单热点编码器)（即在机器学习中使用虚拟变量的表示过程）根据属性的词汇量将属性编码为高维二进制向量。</p>
<ul>
<li>“ Day”属性被编码为7维二进制矢量，而“ Monday”则表示为[1、0、0、0、0、0、0]。 同样，“小时”属性被编码为24维二进制矢量，而“类别”属性被编码为10维二进制矢量。</li>
<li>不对用户ID和轨迹ID进行编码，因为它们仅用于指示该点所属的用户和轨迹。</li>
</ul>
</li>
</ul>
<h4 id="轨迹填充trajectory-padding">轨迹填充Trajectory Padding<a class="header-anchor" href="#轨迹填充trajectory-padding">⁍</a></h4>
<p>在轨迹点编码过程之后，轨迹的所有空间，时间和主题属性都存储在多维矩阵中，多维矩阵的第一维表示每个轨迹的索引。</p>
<p>由于每个轨迹数据的长度（即轨迹点的数量）是变量，因此我们应用轨迹填充技术来确保所有轨迹的长度与最长轨迹的长度相同。</p>
<p><mark>使用零预填充将空轨迹点（即属性均设置为零的点）填充到每个轨迹，直到所有轨迹达到与数据集中最长轨迹相同的长度为止。</mark></p>
<p>主要原因是可以将具有相同大小的数据用于批处理和训练深度学习模型，这将加快训练过程。 在模型训练和推理过程中，这些填充的轨迹点将被屏蔽（即剪切），它们实际上不会影响神经网络权重更新和派生的结果。</p>
<h3 id="2-2-lstm-trajgan-model">2.2 LSTM-TrajGAN Model<a class="header-anchor" href="#2-2-lstm-trajgan-model">⁍</a></h3>
<p><img src="http://www.jinmengrao.com/trajgan/img/LSTM_TrajGAN.png" alt="img"></p>
<ul>
<li>
<p><strong>Trajectory Generator</strong> 轨迹生成器捕获实际轨迹数据的数据分布和模式，并基于其相应的原始轨迹数据和随机噪声生成合成轨迹数据。</p>
</li>
<li>
<p><strong>Trajectory Discriminator</strong> 轨迹鉴别器区分轨迹样本是来自训练集(即真实轨迹数据)还是来自轨迹生成器(即合成轨迹数据)。</p>
</li>
<li>
<p><strong>Trajectory Generator</strong> 轨迹发生器的目标是生成“高质量”的合成轨迹，以“愚弄”轨迹鉴别器，从而导致两个人之间的极小极大博弈。</p>
</li>
<li>
<p>所生成的综合轨迹旨在能够进行时空概要分析，同时具有一定程度的不确定性和随机性，以保护轨迹分析任务中涉及隐私问题的用户隐私。这一思想反映在 LSTM-TrajGAN 模型的设计和优化。</p>
</li>
</ul>
<h4 id="轨迹生成器trajectory-generator">轨迹生成器Trajectory Generator<a class="header-anchor" href="#轨迹生成器trajectory-generator">⁍</a></h4>
<p>五层：</p>
<ol>
<li>
<p>input</p>
<p>编码后的真实轨迹+随机噪声</p>
</li>
<li>
<p>Embedding</p>
<p>多层感知机MLP</p>
<ul>
<li><strong>空间维度</strong>（即成对的经纬度偏差），我们使用 MLP 将它们嵌入到64维向量中</li>
<li><strong>时间维度</strong>（如，天和小时）和<strong>分类属性</strong>（如，POI 类别）：使用MLP分别嵌入它们，并根据其词汇量获得定长向量</li>
<li><strong>几个公式</strong></li>
</ul>
</li>
<li>
<p>Feature Fusion</p>
<ul>
<li>嵌入过程之后，我们将所有矢量和随机噪声进一步连接起来，然后使用dense layer密集层将它们融合为100维矢量。</li>
<li>通过利用特征融合，我们利用了每个轨迹点的所有空间，时间和类别特征，并将它们融合在一起以支持时空轨迹建模和生成</li>
</ul>
</li>
<li>
<p>LSTM Modeling</p>
<ul>
<li>
<p>多对多LSTM结构（many-to-many LSTM structure）</p>
<ul>
<li>该结构将<strong>具有特定时间步长的序列</strong>作为输入，并生成具有与时间步长相同的序列。 事实证明，诸如LSTM的递归模型在时空序列建模和预测中是有效的</li>
</ul>
</li>
<li>
<p>已知融合特征的维数，我们在LSTM模型中分配100个单元，将融合特征输入到模型中</p>
<p><img src="https://gitee.com/Augu1sto/imageHost/raw/master/BlogImg/202112241855102.png" alt="image-20211224185526994"></p>
<p><img src="https://gitee.com/Augu1sto/imageHost/raw/master/BlogImg/202112241855475.png" alt="image-20211224185554422"></p>
<ul>
<li>F: 代表轨迹中所有轨迹点的融合特征</li>
<li>H：LSTM模型的输出，具有与输入相同的时间步长</li>
<li>W<sub>lstm</sub> ： LSTM模型的权重矩阵</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Regression/Classification</p>
<ul>
<li>最后，我们从LSTM建模层的输出H解码合成轨迹数据。 H中的每个特征向量hi是一个100维向量，其中包含合成轨迹点的空间，时间和分类特征。
<ul>
<li>（<strong>空间维度</strong>）为了解码纬度和经度偏差，我们使用具有两个单元的dense layer密集层并使用tanh双曲正切函数。此外，我们进一步扩展了输出范围，以确保其范围涵盖所有可能的偏差值</li>
<li>（<strong>时间维度/分类属性</strong>）为了解码日期，小时和类别属性，我们使用了与词汇量大小一样多的单元的dense layer密集层，并使用softmax归一化指数函数来恢复这些属性的one-Hot表示：</li>
<li><strong>几个公式</strong></li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="轨迹鉴别器">轨迹鉴别器<a class="header-anchor" href="#轨迹鉴别器">⁍</a></h4>
<p>轨迹鉴别器的结构与轨迹生成器非常相似。 它们之间的主要区别是：</p>
<p>（1）鉴别器仅将轨迹数据作为输入（不需要随机噪声）；</p>
<p>（2）我们使用多对一LSTM模型，该模型以具有时间步长的特征作为输入，并以一个标量作为输出：</p>
<p><img src="https://gitee.com/Augu1sto/imageHost/raw/master/BlogImg/202112241856242.png" alt="image-20211224185608191"></p>
<ul>
<li>F: 代表轨迹中所有轨迹点的融合特征</li>
<li>h：LSTM模型的输出标量</li>
<li>W<sub>lstmd</sub> ： LSTM模型的权重矩阵</li>
</ul>
<p>（3）我们使用具有Sigmoid激活函数的一个单元dense layer密集层在标量输出上进行二分类（真实或合成轨迹）：</p>
<p><img src="https://gitee.com/Augu1sto/imageHost/raw/master/BlogImg/202112241856161.png" alt="image-20211224185624111"></p>
<ul>
<li>D<sup>bc</sup>: 用于进行二分类的具有Sigmoid函数的1单元dense layer</li>
<li>W<sup>bc</sup>: 权重矩阵；</li>
<li>O<sub>d</sub>: 鉴别器的最终输出。</li>
</ul>
<h3 id="2-3-轨迹相似度损失的测量-trajloss-for-measuring-trajectory-similarity-losses">2.3 轨迹相似度损失的测量 TrajLoss for Measuring Trajectory Similarity Losses<a class="header-anchor" href="#2-3-轨迹相似度损失的测量-trajloss-for-measuring-trajectory-similarity-losses">⁍</a></h3>
<p>最初的GAN旨在优化以下目标函数：</p>
<p><img src="https://gitee.com/Augu1sto/imageHost/raw/master/BlogImg/202112241857935.png" alt="image-20211224185735887"></p>
<ul>
<li>p<sub>data</sub>(x): 真实数据样本的分布</li>
<li>p<sub>z</sub>(z)： 噪声变量的先验</li>
<li>D(x)：x服从（来自？）p<sub>data</sub>(x)的概率</li>
<li>G(z)：p<sub>z</sub>(z)到p<sub>data</sub>(x)的映射</li>
<li>生成器的目标是最小化后面一项；鉴别器的目标是最大化这两项的和；总体来说就是双方minmax的博弈（？）</li>
</ul>
<p>根据目标函数O（D，G），鉴别器的损失函数可以视为二进制交叉熵（BCE）损失函数（LBCE），也将用于训练生成器。与原始GAN不同，我们需要真实的轨迹数据作为输入。</p>
<p>我们设计了一个<strong>新的损耗度量函数TrajLoss</strong>，以进一步测量真实轨迹数据与合成轨迹数据在空间，时间和分类维度上的相似性损耗，并使用该损耗函数来<strong>训练生成器</strong>。</p>
<p><img src="https://gitee.com/Augu1sto/imageHost/raw/master/BlogImg/202112241857660.png" alt="image-20211224185743614"></p>
<ul>
<li>yr：真实标签</li>
<li>yp：鉴别器的预测结果</li>
<li>tr：真实轨迹</li>
<li>ts：合成轨迹</li>
<li>L<sub>BCE</sub>：鉴别器的原始二进制交叉熵损失</li>
<li>Ls，Lt和Lc分别是真实轨迹和合成轨迹之间的空间相似度损失，时间相似度损失和类别相似度损失；</li>
<li>α，β，γ和c是这些损失的权重，可以针对不同的情况进行不同的分配。</li>
</ul>
<p>在本文中，我们使用L2损失(即最小二乘误差)作为Ls，最近的研究[8]表明L2损耗在测量轨迹空间相似性方面是有效的。</p>
<p>我们选择Softmax交叉熵(SCE)作为Lt和Lc的损失函数，因为在本框架中它们都被视为多分类问题，因此可以使用SCE进行优化。</p>
<p>在模型训练过程中，轨迹损失会更新生成器的权值，以提高合成轨迹数据的质量。</p>
<h2 id="3-experiment">3 Experiment<a class="header-anchor" href="#3-experiment">⁍</a></h2>
<h3 id="3-1-轨迹用户链接（trajectory-user-linking，tul）"><strong>3.1 轨迹用户链接（Trajectory-User Linking，TUL）</strong><a class="header-anchor" href="#3-1-轨迹用户链接（trajectory-user-linking，tul）">⁍</a></h3>
<ul>
<li>针对<strong>RQ1</strong>，评估隐私保护有效性</li>
</ul>
<p>它从轨迹中识别用户并将轨迹链接到他们[4]。 在具有地理标签的社交媒体应用中，TUL是一项必不可少的任务，并且受到越来越多的隐私关注[4，30，21]。</p>
<ul>
<li>可以将评估视为<strong>对抗性实验</strong>：我们训练LSTM-TrajGAN模型，并使用生成的合成轨迹来抑制最新的TUL算法的准确性。</li>
<li>与其他两种常用的位置隐私保护方法进行比较：<strong>随机扰动</strong>和<strong>高斯地理掩蔽</strong>。</li>
</ul>
<h4 id="dataset">Dataset<a class="header-anchor" href="#dataset">⁍</a></h4>
<p>NYC Foursquare weekly trajectory dataset</p>
<ul>
<li>193 users, 3,079 trajectories and 66,962 trajectory points</li>
<li>2/3训练，1/3测试</li>
</ul>
<p><img src="https://gitee.com/Augu1sto/imageHost/raw/master/BlogImg/202112241858244.png" alt="image-20211224185802193"></p>
<h4 id="training-and-evaluation">Training and Evaluation<a class="header-anchor" href="#training-and-evaluation">⁍</a></h4>
<h5 id="轨迹合成">轨迹合成<a class="header-anchor" href="#轨迹合成">⁍</a></h5>
<p>我们使用几个默认的训练超参数在训练集上训练了2,000个周期的LSTM-TrajGAN模型（例如，我们使用学习率为0.001的adam优化器并将批次大小设置为256）。 在训练过程之后，来自测试集的轨迹数据以及随机噪声随后被用作发生器的输入以获得合成轨迹数据。</p>
<p><img src="http://www.jinmengrao.com/trajgan/img/TRAJGAN3.png" alt="img"></p>
<p>图4显示了来自测试数据的真实轨迹及其模型生成的相应合成轨迹的可视化示例。</p>
<h5 id="使用最先进的tul算法marc（多方面trajectory分类器-21-）对测试数据和合成数据执行tul任务">使用最先进的TUL算法MARC（多方面tRajectory分类器[21]）对测试数据和合成数据执行TUL任务<a class="header-anchor" href="#使用最先进的tul算法marc（多方面trajectory分类器-21-）对测试数据和合成数据执行tul任务">⁍</a></h5>
<p><img src="https://gitee.com/Augu1sto/imageHost/raw/master/BlogImg/202112241858704.png" alt="image-20211224185812642"></p>
<p>使用五个常用指标评估TUL的准确性：</p>
<ul>
<li>
<p>ACC @ 1（Top-1准确性，表明模型具有将正确标签作为最可能的标签候选者的能力）</p>
</li>
<li>
<p>ACC @ 5（Top- 5精度，显示模型在前5个最可能的标签候选者中具有正确标签的能力，</p>
</li>
<li>
<p>（多分类模型的评价指标）</p>
<ul>
<li>Macro-P（所有类别之间的平均精度）</li>
<li>Macro-R（所有类别之间的平均召回率）</li>
<li>Macro-F1（Macro-P和Macro-R的谐波均值）。</li>
</ul>
</li>
<li>
<p>RP：随机扰动</p>
</li>
<li>
<p>Gaussuain：高斯地理掩蔽Geomasking</p>
</li>
</ul>
<p>结果（TUL精度越高，轨迹隐私保护的能力越差）</p>
<ul>
<li>由LSTM-TrajGAN生成的综合数据成功地将四个指标（ACC @ 1，Macro-P，Macro-R和Macro-F）中的得分从0.900抑制到0.400左右。</li>
<li>结果表明，我们的模型可以通过分析轨迹有效地防止用户被识别。 此外，随机扰动在保护有关TUL任务的轨迹隐私方面的效果有限，并且高斯地理遮罩的效果更好，但得分仍高于我们的模型。</li>
<li>结果还表明，与仅使用空间维相比，同时利用轨迹的空间和时间维可同时带来更好的隐私保护性能。</li>
</ul>
<h3 id="3-2-合成轨迹特征分析synthetic-trajectory-characteristics-analysis">3.2 合成轨迹特征分析Synthetic Trajectory Characteristics Analysis<a class="header-anchor" href="#3-2-合成轨迹特征分析synthetic-trajectory-characteristics-analysis">⁍</a></h3>
<ul>
<li>针对<strong>RQ2</strong>，评估合成的轨迹的可用性</li>
</ul>
<h4 id="空间特征spatial-characteristics">空间特征Spatial Characteristics<a class="header-anchor" href="#空间特征spatial-characteristics">⁍</a></h4>
<p><img src="https://gitee.com/Augu1sto/imageHost/raw/master/BlogImg/202112241858899.png" alt="image-20211224185829840"></p>
<p>基于两个度量标准探索空间特征：Hausdorff距离和Jaccard指数。</p>
<ul>
<li>Hausdorff距离是用于度量公制空间中两个点集之间距离的度量，已被广泛用于度量两个轨迹之间的<strong>空间差异</strong>。</li>
<li>杰卡德系数（Jaccard Index），也称为联合相交，是一种有效的度量，用于测量两个样本集或区域重叠的程度，我们用它来指示两个轨迹之间活动空间的<strong>相似性</strong>[18]。</li>
</ul>
<p>我们计算每对原始轨迹和合成轨迹之间的Hausdorff距离。 同样，由于凸包通常可以代表LBS用户的活动空间，因此我们还计算了它们的凸包之间的Jaccard索引[16]。 表3汇总了这些指标。</p>
<p><strong>【结论】</strong></p>
<p>它表明<strong>随机扰动</strong>具有最小的平均Hausdorff距离（0.004）和最大的平均Jaccard指数（0.763），这是有道理的，因为它仅对轨迹的空间维度产生有限的影响。 尽管这种方法可以很好地保留空间相似性，但是却牺牲了位置保密性。</p>
<p>我们的模型在这两个指标上的表现<strong>优于高斯地理掩蔽</strong>，并且还更好地抑制了上述TUL指标，从而在空间相似性和位置隐私之间取得了更好的平衡。</p>
<h4 id="时序特征temporal-characteristics">时序特征Temporal Characteristics<a class="header-anchor" href="#时序特征temporal-characteristics">⁍</a></h4>
<p>我们还探讨了时间特征的基础上可视化的两个概要指标: 时间访问概率分布为每个 POI 类别，和 总体时间访问频率分布。</p>
<p><img src="https://gitee.com/Augu1sto/imageHost/raw/master/BlogImg/202112241858610.png" alt="image-20211224185846538"></p>
<p>我们计算原始轨迹中<strong>每小时每个 POI 类别的访问次数</strong>，并使用3种不同的方法计算合成轨迹，然后将它们转换成概率分布矩阵(图5) ，在其中可以分析和比较时间模式和时间相似性。</p>
<p><strong>【结论】</strong></p>
<p>结果表明，LSTM-TrajGAN的时间访问概率分布与原始数据具有很大的共性，体现出明显的时间相似性。</p>
<p>LSTM-TrajGAN的结果的某些部分（即类别C和E）具有接近零的访问概率，因为这些类别很少出现在训练数据中，因此模型无法学习到足够的信息来对其进行智能预测。</p>
<p><img src="https://gitee.com/Augu1sto/imageHost/raw/master/BlogImg/202112241859123.png" alt="image-20211224185905063"></p>
<p>此外，我们调查了总体时间和分类访问频率分布（图6a和图6b）。 与随机扰动（0.536）和高斯地质掩蔽（0.535）相比，我们模型的总体时间访问频率分布可以更好地拟合原始数据（皮尔逊系数：0.761）。 总体分类访问频率分布也很合适（0.889）。</p>
<p><strong>【结论】</strong></p>
<p>因此，我们得出结论，我们的模型通常很好地保留了时间和类别特征。</p>
<h2 id="discussion">Discussion<a class="header-anchor" href="#discussion">⁍</a></h2>
<p>本节讨论可能影响LSTM-TrajGAN模型的隐私保护有效性的因素，以及隐私保护有效性与实用程序之间的权衡。 最后，我们讨论了该方法的局限性。</p>
<h3 id="4-1-factors-aﬀecting-privacy-protection-eﬀectiveness">4.1 Factors Aﬀecting Privacy Protection Eﬀectiveness<a class="header-anchor" href="#4-1-factors-aﬀecting-privacy-protection-eﬀectiveness">⁍</a></h3>
<ul>
<li>训练和最优化的设置（参数）</li>
<li>空间嵌入方法
<ul>
<li>MLP：嵌入每个人的位置以获得固定长度的向量，并将该向量用作LSTM模型的输入以生成人类轨迹。</li>
<li>Geohash：首先使用Geohash算法将区域划分为网格单元，然后将纬度和经度编码为字符串，最后将字符串转换为二进制固定长度向量作为字符串。 每个轨迹点的空间尺寸的表示形式。</li>
<li>本文中的MLP：从所有轨迹位置的质心得出纬度和经度的偏差，而不是直接嵌入坐标，然后使用MLP将这些偏差嵌入到64维向量中。
<ul>
<li>目标是生成合成轨迹，这意味着我们需要从模型中的隐藏特征中解码出坐标，因此 使用二进制Geohash可能导致学习坐标的有效表示，设计适当的空间损失以及错误的反向传播方面的困难</li>
<li>与[8]中的笛卡尔坐标系所描述的受限预测区域不同，我们任务中的预测区域位于城市规模上，并且两个GPS坐标之间的差异仅在小数点后出现 。 对于模型来说，仅需细微的变化就可以学习和预测坐标，这将是一个巨大的挑战。 因此，我们对坐标进行了<strong>标准化</strong>，以使两个位置之间的差异对于模型的学习更为重要。</li>
</ul>
</li>
<li>空间嵌入维度对TULtask中的指标的影响（较高维的较好：表4）
<ul>
<li>高维空间中的向量通常能够提取和嵌入更多信息。 但是，由于物理设备的限制，这还涉及在位置精度和计算工作量之间进行权衡。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="4-2-隐私保护有效性与实用性之间的权衡">4.2 隐私保护有效性与实用性之间的权衡<a class="header-anchor" href="#4-2-隐私保护有效性与实用性之间的权衡">⁍</a></h3>
<p><img src="https://gitee.com/Augu1sto/imageHost/raw/master/BlogImg/202112241859863.png" alt="image-20211224185923801"></p>
<p>值得注意的是，每种方法的位置都是根据我们的实验估算得出的。 我们认为，考虑这种关系将有助于针对特定情况选择和设计适当的轨迹隐私保护方法。</p>
<h3 id="4-3-局限性">4.3 局限性<a class="header-anchor" href="#4-3-局限性">⁍</a></h3>
<ul>
<li><strong>计算量更大</strong>：首先，与使现有轨迹模糊的传统地理掩蔽技术相比，我们生成新轨迹的深度学习模型导致计算量大得多，并且在部署到应用程序中之前还需要额外的训练过程。</li>
<li>其次，我们专注于TUL任务并分析了合成轨迹的时空特征，这反映了它们在保护隐私轨迹分析方面的潜力，但尚未研究更具体的评估。</li>
<li>第三，我们的模型仅生成具有与原始轨迹相同长度的合成轨迹。 最后，我们的模型目前关注的是城市规模的轨迹，基于偏差的位置表示<strong>可能不适用于全球规模的轨迹</strong>。</li>
</ul>
<p>这些限制将在我们的未来工作中进一步探讨。</p>
<h2 id="总结与未来工作">总结与未来工作<a class="header-anchor" href="#总结与未来工作">⁍</a></h2>
<p>这项研究提出了一种新颖的LSTM-TrajGAN方法，即结合LSTM递归神经网络和GAN结构以生成用于轨迹数据发布的隐私保护合成轨迹的深度学习模型。</p>
<p>在模型设计中利用对抗训练的思想，在Foursquare NYCweekly轨迹数据集上训练模型，并评估其在TUL任务中的隐私保护有效性。</p>
<p>关于我们在研究开始时提出的两个研究问题，结果表明（RQ1）我们的模型可以生成时空综合轨迹，从而在一定程度上阻止了轨迹创建者（即用户）的重新识别，并且 （RQ2）保留原始轨迹的某些空间，时间和主题特征。</p>
<p>此外，结果表明该模型具有支持进一步的空间或时间分析的潜力。 最后，我们探讨了影响隐私保护有效性的因素，并讨论了模型有效性和效用之间的一般取舍。</p>
<p>新损失函数TrajLoss的设计为推进GeoAI的空间显式人工智能技术的发展提供了新新的见解[13]。</p>
<p>我们未来的工作将集中在<strong>改进轨迹相似度损失度量</strong>功能，将我们的框架<strong>扩展到全球规模的轨迹数据集</strong>，生成自定义可变长度的合成轨迹数据，探索潜在的隐私攻击和防御策略以及评估隐私保护的有效性和实用性。 我们在其他轨迹数据挖掘和分析任务中的模型。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Augu1sto</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://augu1sto.github.io/augu1sto/30e8bf2b6dab/">https://augu1sto.github.io/augu1sto/30e8bf2b6dab/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://augu1sto.github.io/augu1sto" target="_blank">若叶</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/augu1sto/tags/%E8%BD%A8%E8%BF%B9/">轨迹</a><a class="post-meta__tags" href="/augu1sto/tags/%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4/">隐私保护</a><a class="post-meta__tags" href="/augu1sto/tags/GAN/">GAN</a></div><div class="post_share"><div class="social-share" data-image="/augu1sto/img/cover02.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/augu1sto/a66cd27703a0/"><img class="prev-cover" src="/augu1sto/img/cover05.jpg" onerror="onerror=null;src='/augu1sto/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">JAVA学习（三）| JAVA核心类</div></div></a></div><div class="next-post pull-right"><a href="/augu1sto/8cb18cd4baea/"><img class="next-cover" src="/augu1sto/img/cover02.jpg" onerror="onerror=null;src='/augu1sto/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">【面试-线程相关】i++在两个线程分别执行100次，最大值和最小值分别多少</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/augu1sto/514bb2d87420/" title="【论文阅读|TrajGen】KDD21'Generating Mobility Trajectories with Retained Data Utility"><img class="cover" src="/augu1sto/img/cover05.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-23</div><div class="title">【论文阅读|TrajGen】KDD21'Generating Mobility Trajectories with Retained Data Utility</div></div></a></div><div><a href="/augu1sto/b8163cc89113/" title="【论文阅读】TrajGAIL·Generating urban vehicle trajectories using  generative adversarial imitation learning"><img class="cover" src="/augu1sto/img/cover04.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-06</div><div class="title">【论文阅读】TrajGAIL·Generating urban vehicle trajectories using  generative adversarial imitation learning</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/augu1sto/img/avatar.png" onerror="this.onerror=null;this.src='/augu1sto/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Augu1sto</div><div class="author-info__description">Articles | Notes | Ideas</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/augu1sto/archives/"><div class="headline">文章</div><div class="length-num">79</div></a></div><div class="card-info-data-item is-center"><a href="/augu1sto/tags/"><div class="headline">标签</div><div class="length-num">58</div></a></div><div class="card-info-data-item is-center"><a href="/augu1sto/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/augu1sto"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/augu1sto" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:yingu081@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://codepen.io/augu1sto" target="_blank" title="CodePen"><i class="fab fa-codepen"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">【缓慢重新建站中】https://github.com/augu1sto/e31c317e1400/</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF"><span class="toc-number">1.</span> <span class="toc-text">论文基本信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#abstract"><span class="toc-number">2.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-introduction"><span class="toc-number">3.</span> <span class="toc-text">1. Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E8%83%8C%E6%99%AF"><span class="toc-number">3.1.</span> <span class="toc-text">问题背景</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E4%BD%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%EF%BC%88lbs-location-based-services%EF%BC%89%E5%B8%A6%E6%9D%A5%E7%9A%84%E9%9A%90%E7%A7%81%E9%97%AE%E9%A2%98"><span class="toc-number">3.1.1.</span> <span class="toc-text">基于位置服务（LBS, Location-Based Services）带来的隐私问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%8C%91%E6%88%98%EF%BC%9F"><span class="toc-number">3.1.2.</span> <span class="toc-text">问题挑战？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%B0%E6%9C%89%E7%A0%94%E7%A9%B6"><span class="toc-number">3.2.</span> <span class="toc-text">现有研究</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E6%8F%90%E5%87%BA"><span class="toc-number">3.3.</span> <span class="toc-text">方法提出</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%A4%E4%B8%AA%E7%A0%94%E7%A9%B6%E9%97%AE%E9%A2%98%EF%BC%88rq%EF%BC%89"><span class="toc-number">3.3.1.</span> <span class="toc-text">两个研究问题（RQ）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E8%B4%A1%E7%8C%AE"><span class="toc-number">3.4.</span> <span class="toc-text">主要贡献</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-method"><span class="toc-number">4.</span> <span class="toc-text">2. Method</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-trajectory-encoding"><span class="toc-number">4.1.</span> <span class="toc-text">2.1 Trajectory Encoding</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BD%A8%E8%BF%B9%E7%82%B9%E7%BC%96%E7%A0%81trajectory-point-encoding"><span class="toc-number">4.1.1.</span> <span class="toc-text">轨迹点编码Trajectory Point Encoding</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BD%A8%E8%BF%B9%E5%A1%AB%E5%85%85trajectory-padding"><span class="toc-number">4.1.2.</span> <span class="toc-text">轨迹填充Trajectory Padding</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-lstm-trajgan-model"><span class="toc-number">4.2.</span> <span class="toc-text">2.2 LSTM-TrajGAN Model</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BD%A8%E8%BF%B9%E7%94%9F%E6%88%90%E5%99%A8trajectory-generator"><span class="toc-number">4.2.1.</span> <span class="toc-text">轨迹生成器Trajectory Generator</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BD%A8%E8%BF%B9%E9%89%B4%E5%88%AB%E5%99%A8"><span class="toc-number">4.2.2.</span> <span class="toc-text">轨迹鉴别器</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E8%BD%A8%E8%BF%B9%E7%9B%B8%E4%BC%BC%E5%BA%A6%E6%8D%9F%E5%A4%B1%E7%9A%84%E6%B5%8B%E9%87%8F-trajloss-for-measuring-trajectory-similarity-losses"><span class="toc-number">4.3.</span> <span class="toc-text">2.3 轨迹相似度损失的测量 TrajLoss for Measuring Trajectory Similarity Losses</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-experiment"><span class="toc-number">5.</span> <span class="toc-text">3 Experiment</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E8%BD%A8%E8%BF%B9%E7%94%A8%E6%88%B7%E9%93%BE%E6%8E%A5%EF%BC%88trajectory-user-linking%EF%BC%8Ctul%EF%BC%89"><span class="toc-number">5.1.</span> <span class="toc-text">3.1 轨迹用户链接（Trajectory-User Linking，TUL）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#dataset"><span class="toc-number">5.1.1.</span> <span class="toc-text">Dataset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#training-and-evaluation"><span class="toc-number">5.1.2.</span> <span class="toc-text">Training and Evaluation</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BD%A8%E8%BF%B9%E5%90%88%E6%88%90"><span class="toc-number">5.1.2.1.</span> <span class="toc-text">轨迹合成</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E6%9C%80%E5%85%88%E8%BF%9B%E7%9A%84tul%E7%AE%97%E6%B3%95marc%EF%BC%88%E5%A4%9A%E6%96%B9%E9%9D%A2trajectory%E5%88%86%E7%B1%BB%E5%99%A8-21-%EF%BC%89%E5%AF%B9%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E5%92%8C%E5%90%88%E6%88%90%E6%95%B0%E6%8D%AE%E6%89%A7%E8%A1%8Ctul%E4%BB%BB%E5%8A%A1"><span class="toc-number">5.1.2.2.</span> <span class="toc-text">使用最先进的TUL算法MARC（多方面tRajectory分类器[21]）对测试数据和合成数据执行TUL任务</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E5%90%88%E6%88%90%E8%BD%A8%E8%BF%B9%E7%89%B9%E5%BE%81%E5%88%86%E6%9E%90synthetic-trajectory-characteristics-analysis"><span class="toc-number">5.2.</span> <span class="toc-text">3.2 合成轨迹特征分析Synthetic Trajectory Characteristics Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A9%BA%E9%97%B4%E7%89%B9%E5%BE%81spatial-characteristics"><span class="toc-number">5.2.1.</span> <span class="toc-text">空间特征Spatial Characteristics</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%B6%E5%BA%8F%E7%89%B9%E5%BE%81temporal-characteristics"><span class="toc-number">5.2.2.</span> <span class="toc-text">时序特征Temporal Characteristics</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#discussion"><span class="toc-number">6.</span> <span class="toc-text">Discussion</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-factors-a%EF%AC%80ecting-privacy-protection-e%EF%AC%80ectiveness"><span class="toc-number">6.1.</span> <span class="toc-text">4.1 Factors Aﬀecting Privacy Protection Eﬀectiveness</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%9C%89%E6%95%88%E6%80%A7%E4%B8%8E%E5%AE%9E%E7%94%A8%E6%80%A7%E4%B9%8B%E9%97%B4%E7%9A%84%E6%9D%83%E8%A1%A1"><span class="toc-number">6.2.</span> <span class="toc-text">4.2 隐私保护有效性与实用性之间的权衡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">6.3.</span> <span class="toc-text">4.3 局限性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E4%B8%8E%E6%9C%AA%E6%9D%A5%E5%B7%A5%E4%BD%9C"><span class="toc-number">7.</span> <span class="toc-text">总结与未来工作</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/augu1sto/eb3eaf548f9c/" title="test"><img src="/augu1sto/img/cover01.jpg" onerror="this.onerror=null;this.src='/augu1sto/img/404.jpg'" alt="test"/></a><div class="content"><a class="title" href="/augu1sto/eb3eaf548f9c/" title="test">test</a><time datetime="2022-12-11T17:32:20.000Z" title="发表于 2022-12-12 01:32:20">2022-12-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/augu1sto/aba77dc25685/" title="test-12"><img src="/augu1sto/img/cover02.jpg" onerror="this.onerror=null;this.src='/augu1sto/img/404.jpg'" alt="test-12"/></a><div class="content"><a class="title" href="/augu1sto/aba77dc25685/" title="test-12">test-12</a><time datetime="2022-12-11T15:15:35.000Z" title="发表于 2022-12-11 23:15:35">2022-12-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/augu1sto/e31c317e1400/" title="【公告】重新建站ING..."><img src="/augu1sto/img/cover01.jpg" onerror="this.onerror=null;this.src='/augu1sto/img/404.jpg'" alt="【公告】重新建站ING..."/></a><div class="content"><a class="title" href="/augu1sto/e31c317e1400/" title="【公告】重新建站ING...">【公告】重新建站ING...</a><time datetime="2022-11-30T13:52:27.000Z" title="发表于 2022-11-30 21:52:27">2022-11-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/augu1sto/45f675fda3f8/" title="Array.prototype.unshift方法详解"><img src="/augu1sto/img/cover03.jpg" onerror="this.onerror=null;this.src='/augu1sto/img/404.jpg'" alt="Array.prototype.unshift方法详解"/></a><div class="content"><a class="title" href="/augu1sto/45f675fda3f8/" title="Array.prototype.unshift方法详解">Array.prototype.unshift方法详解</a><time datetime="2022-09-05T11:56:53.000Z" title="发表于 2022-09-05 19:56:53">2022-09-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/augu1sto/4cf012bad379/" title="深拷贝"><img src="/augu1sto/img/cover01.jpg" onerror="this.onerror=null;this.src='/augu1sto/img/404.jpg'" alt="深拷贝"/></a><div class="content"><a class="title" href="/augu1sto/4cf012bad379/" title="深拷贝">深拷贝</a><time datetime="2022-09-03T12:28:50.000Z" title="发表于 2022-09-03 20:28:50">2022-09-03</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Augu1sto</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/augu1sto/js/utils.js"></script><script src="/augu1sto/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="/augu1sto/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><div class="aplayer no-destroy" data-id="6990698783" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-listFolded="false" data-order="random" data-preload="none" data-autoplay="false" muted></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="true" data-click="true"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  '#config-diff',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if (false) {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.removeEventListener('scroll', window.tocScrollFn)
  window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // Analytics
  if (false) {
    MtaH5.pgv()
  }

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/augu1sto/live2dw/lib/L2Dwidget.min.js?b0f017d930c51acc4f4f9e757bdd83e9"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/augu1sto/live2dw/assets/kasumi_event128.model.json"},"display":{"superSample":2,"width":200,"height":400,"position":"right","hOffset":30,"vOffset":0},"mobile":{"show":false,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"dialog":{"enable":true,"text":["kira kira doki doki","大家我全都喜欢","poppipa pippopa"]},"log":false});</script></body></html>